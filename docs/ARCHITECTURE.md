# Архитектура AI Code Review Assistant

## Общая схема

```
┌─────────────────────────────────────────────────────────────┐
│                      GitLab Workflow                         │
└─────────────────────────────────────────────────────────────┘
                             │
                             │ Webhook Event
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                     FastAPI Backend                          │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  main.py - Entry point & webhook handler            │   │
│  └──────────────┬────────────────────────────────────────┘  │
│                 │                                            │
│     ┌───────────┴───────────┐                               │
│     ▼                       ▼                               │
│  ┌──────────────┐    ┌──────────────┐                      │
│  │GitLabClient  │    │CodeAnalyzer  │                      │
│  └──────┬───────┘    └──────┬───────┘                      │
│         │                    │                               │
│         │                    ▼                               │
│         │            ┌──────────────┐                       │
│         │            │LLMProvider   │                       │
│         │            │ - OpenAI     │                       │
│         │            │ - Gemini     │                       │
│         │            │ - Claude     │                       │
│         │            └──────────────┘                       │
│         │                                                    │
│         ▼                                                    │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  GitLab API - Post comments & update labels          │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                    PostgreSQL Database                       │
│            (Statistics & History - optional)                 │
└─────────────────────────────────────────────────────────────┘
```

## Компоненты системы

### 1. main.py - Точка входа
**Ответственность:**
- Инициализация FastAPI приложения
- Обработка webhook'ов от GitLab
- Координация между компонентами
- Управление жизненным циклом приложения

**Основные endpoints:**
- `GET /` - Health check
- `GET /health` - Статус системы
- `POST /webhook/gitlab` - Прием webhook от GitLab
- `GET /stats` - Статистика (для dashboard)

### 2. config.py - Конфигурация
**Ответственность:**
- Загрузка переменных окружения
- Валидация конфигурации
- Централизованное хранение настроек

**Основные параметры:**
- GitLab credentials
- LLM provider настройки
- Database connection
- Application settings

### 3. models.py - Модели данных
**Ответственность:**
- Определение структур данных
- Валидация через Pydantic
- Типизация для type safety

**Основные модели:**
- `CodeIssue` - Одна проблема в коде
- `AnalysisResult` - Результат анализа
- `WebhookPayload` - Данные от GitLab
- `CodeReviewRecord` - Запись в БД

### 4. gitlab_client.py - Клиент GitLab
**Ответственность:**
- Взаимодействие с GitLab API
- Получение информации о MR
- Публикация комментариев
- Управление метками

**Основные методы:**
- `get_merge_request()` - Получить MR
- `get_mr_changes()` - Получить diff
- `post_review_comments()` - Опубликовать ревью
- `update_mr_labels()` - Обновить метки

### 5. llm_provider.py - Провайдеры LLM
**Ответственность:**
- Абстракция для работы с разными LLM
- Унифицированный интерфейс
- Обработка ошибок API

**Поддерживаемые провайдеры:**
- OpenAI (GPT-4o-mini) - основной
- Google Gemini - альтернатива
- Anthropic Claude - опциональный

**Паттерн:**
```python
class LLMProvider(ABC):
    @abstractmethod
    async def analyze_code(self, prompt: str) -> Dict
```

### 6. code_analyzer.py - Анализатор кода
**Ответственность:**
- Подготовка кода для анализа
- Формирование промптов
- Парсинг ответов LLM
- Подсчет статистики

**Процесс анализа:**
1. Форматирование diff в читаемый вид
2. Обрезка если код слишком большой
3. Генерация промпта с контекстом
4. Вызов LLM с timeout
5. Парсинг JSON ответа
6. Подсчет проблем по severity

### 7. prompts.py - Промпты для LLM
**Ответственность:**
- Хранение шаблонов промптов
- Настройка под разные контексты
- Инструкции для LLM

**Основной промпт:**
- Роль: senior developer в банке
- Контекст: банковское приложение
- Критерии: безопасность, производительность, баги, читаемость
- Формат ответа: строгий JSON

### 8. database.py - База данных
**Ответственность:**
- Подключение к PostgreSQL
- ORM модели (SQLAlchemy)
- Сохранение истории анализов
- Данные для статистики

**Таблица code_reviews:**
- ID анализа
- MR информация
- Метрики (score, issues count)
- Сэкономленное время
- Дата и автор

## Поток данных

### 1. Webhook от GitLab
```python
{
    "object_kind": "merge_request",
    "object_attributes": {
        "iid": 123,
        "action": "open",
        "title": "Add new feature"
    },
    "project": {
        "id": 456
    }
}
```

### 2. Получение изменений
```python
changes = [
    {
        "old_path": "file.py",
        "new_path": "file.py",
        "diff": "@@ -10,3 +10,5 @@\n-old code\n+new code"
    }
]
```

### 3. Анализ LLM
```python
{
    "summary": "Добавлена функция X...",
    "score": 7.5,
    "issues": [
        {
            "line": 45,
            "severity": "critical",
            "description": "SQL injection",
            "suggestion": "Use parameterized queries"
        }
    ],
    "recommendation": "needs_fixes"
}
```

### 4. Публикация в GitLab
- Summary comment вверху MR
- Inline комментарии к проблемным строкам
- Обновление labels (ai-approved, ai-needs-fixes)

## Безопасность

### Аутентификация
- Webhook: секретный токен в header
- GitLab API: Personal Access Token
- LLM API: API keys в environment

### Валидация
- Проверка webhook signature
- Валидация JSON через Pydantic
- Sanitization входных данных

### Rate Limiting
- Ограничение частоты webhook
- Timeout для LLM (300 сек)
- Ограничение размера кода (50K символов)

## Масштабируемость

### Текущая версия (MVP)
- Синхронная обработка
- Один воркер FastAPI
- Подходит для 10-50 MR в день

### Будущие улучшения
- Очередь задач (Celery/Redis)
- Несколько воркеров
- Кеширование результатов
- Batch processing

## Мониторинг

### Логирование
- Структурированные логи
- Уровни: INFO, WARNING, ERROR
- Логи всех API вызовов

### Метрики
- Время анализа
- Количество проблем
- Успешность API вызовов
- Сэкономленное время

## Расширяемость

### Добавление нового LLM провайдера
```python
class NewLLMProvider(LLMProvider):
    async def analyze_code(self, prompt: str):
        # Реализация
        pass
```

### Кастомные правила проверки
- Файл `.codereview-rules.yaml` в проекте
- Загружается при анализе
- Включается в промпт

### Интеграция с другими системами
- Jira (связь задач с MR)
- Slack (уведомления)
- Prometheus (метрики)
